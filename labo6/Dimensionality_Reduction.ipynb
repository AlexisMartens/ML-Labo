{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Dimensionality reduction and working with textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a dataset $X$, containing $N$ samples with $d$ features. This means that $X$ is matrix of size $N$ x $d$. You can think of this matrix as containing $N$ vectors in a $d$-dimensional space. Each feature is thus a dimension of the input data.\n",
    "\n",
    "So far, we have mostly used datasets where $d$ is relatively small. Realistic datasets usually have much larger input dimensions $d$. Often, as a preprocessing step, you will reduce the dimensionality of the dataset. There are several reasons for doing so:\n",
    "* In most learning algorithms, the complexity depends on both $N$ and $d$. By reducing the dimensionality of the problem, we can reduce memory and computation.\n",
    "* Simpler models can be more robust on small datasets. \n",
    "* When data can be explained with fewer features, we get a better idea about the process that underlies the data.\n",
    "* When data can be represented in a few dimensions without loss of information, it can be plotted and analyzed visually for structure and outliers.\n",
    "\n",
    "There are two main methods for reducing dimensionality: feature *selection* and feature *extraction*. In feature selection, we are interested in finding $k < d$ dimensions, that give us the most information, and we simply discard the other $(d-k)$ dimensions. This means that we are removing $k$ columns from the $X$ matrix, leaving the other columns unmodified. In feature derivation, we are interesting in finding a **new** set of $k$ dimensions that are combinations of the original $d$ dimensions. \n",
    "This means that we will not simply discard a number of dimensions from the input data, but transform each original datapoint (in $N$-dimensional space) to a point in a $k$-dimensional space. \n",
    "\n",
    "Mathematically, this means we need to find a $k$ x $d$ matrix $W$ to transform $X$ into a $N$ x $k$ matrix $X_{new}$:\n",
    "$$\n",
    "X_{new} = X.W^T\n",
    "$$\n",
    "\n",
    "In this lab session, we will focus on **Principal Component Analysis (PCA)**. This is an unsupervised and unparameterized ML method for **dimensionality reduction**.\n",
    "Dimensionality reduction can be seen as a lossy compression technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a good set of new dimensions to represent the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we need to find a good set of $k$ dimensions. Before delving into the mathematical principles on how to do this, let us first get some intuition by considering an elementary example.\n",
    "\n",
    "Suppose we have a dataset $X$, containing $N=150$ samples with $d=2$ features. Since $d=2$, we can visualize this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X:  (150, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import generate_anisotropicgaussian, plot2DScatter\n",
    "X = generate_anisotropicgaussian(150,2)    \n",
    "plot2DScatter(X)\n",
    "\n",
    "print('Dimension of X: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit an ellipsoid around this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import plotscatterwithellipse\n",
    "    \n",
    "plotscatterwithellipse(X,xmin=5,xmax=10,ymin=1,ymax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The centre of the ellipsoid is the centroid of the data. The axes of this ellipsoid are called the **principal components** of this data. They are the **directions of highest variance**. The first principal component is the red axis $z_1$ on the figure above. We can now use the axes $z_1$ and $z_2$ as a new coordinate system. Each datapoint will have new coordinates in this system.\n",
    "\n",
    "Finding the principal components could thus be seen as first centering the dataset (subtracting the mean along each feature dimension) and then rotating the axes of the coordinate system to line up with the directions of the highest variance. Mathematically, we say that we **project** the data onto the new coordinate system. The plot below shows the centered and lined-up ellips, with each datapoint $x$ now having coordinates in the new coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import plotProjection\n",
    "plotProjection(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the plot above. Suppose we would represent each datapoint with only one feature: $z_1$. We would reduce the dimension of our dataset from $d=2$ to $d=1$, without loosing a lot of relevant information. In this particular example, the variance along $z_2$ may even be due from noise. \n",
    "\n",
    "What we have done in the above is to identify the 2 directions of largest variance (the axes of the ellipse) of 2-dimensional data, and projected our data on these principal components. We then concluded that we could keep only a subset of the features in this new coordinate system (in particular, only one dimension) without losing much of information. This is exactly the idea of **Principal Component Analysis for dimensionality reduction**. \n",
    "\n",
    "To generalize this to higher dimensional data ($d > 2$), we need to find answers to the following questions:\n",
    "* how can we find the $d$ directions of largest variance (the principal components)\n",
    "* how much information do we loose if we only keep $k < d$ directions of largest variance.\n",
    "\n",
    "This is studied in the sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data: breast cancer dataset \n",
    "To experiment with PCA we will use a dataset with a large number of characteristics of the cell nuclei from breast biopsy. This dataset was constructed for exercises on binary classification: each data item is labeled as 'benign' (no cancer) or 'malign'. You can also use it from clustering tasks where you hope to group all the benign samples together in one cluster and the malign samples in another cluster. In this exercise, we will use it for dimensionality reduction. The 30 features make it impossible to visually inspect the data. We will transform the 30 dimensional feature representation into a lower dimensional one that is easier to interpret for a human but hopefully also for a downstream machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of dataset: \n",
      "(569, 30)\n",
      "(569,)\n",
      "First elements in the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print('Dimensions of dataset: ')\n",
    "print(cancer.data.shape)\n",
    "print(cancer.target.shape)\n",
    "\n",
    "df = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
    "\n",
    "print('First elements in the dataset:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "To apply PCA, we need to perform the following steps:\n",
    "1. Normalize the dataset.\n",
    "2. Compute the covariance matrix of the whole dataset.\n",
    "3. Compute eigenvectors and the corresponding eigenvalues.\n",
    "4. Sort the eigenvectors by decreasing eigenvalues and choose k eigenvectors with the largest eigenvalues to form a d × k dimensional matrix W.\n",
    "5. Use this d × k eigenvector matrix to transform the samples onto the new subspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: dataset normalization\n",
    "For PCA to work properly, you have to subtract the mean from each of the data dimensions. The code below uses the *StandardScaler* from Scikit-learn. This also normalizes the data to have a standard deviation of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
       "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
       "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
       "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
       "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          3.283515        2.652874             2.532475       2.217515   \n",
       "1         -0.487072       -0.023846             0.548144       0.001392   \n",
       "2          1.052926        1.363478             2.037231       0.939685   \n",
       "3          3.402909        1.915897             1.451707       2.867383   \n",
       "4          0.539340        1.371011             1.428493      -0.009560   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                2.255747  ...      1.886690      -1.359293         2.303601   \n",
       "1               -0.868652  ...      1.805927      -0.369203         1.535126   \n",
       "2               -0.398008  ...      1.511870      -0.023974         1.347475   \n",
       "3                4.910919  ...     -0.281464       0.133984        -0.249939   \n",
       "4               -0.562450  ...      1.298575      -1.466770         1.338539   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0    2.001237          1.307686           2.616665         2.109526   \n",
       "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2    1.456285          0.527407           1.082932         0.854974   \n",
       "3   -0.550021          3.394275           3.893397         1.989588   \n",
       "4    1.220724          0.220556          -0.313395         0.613179   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0              2.296076        2.750622                 1.937015  \n",
       "1              1.087084       -0.243890                 0.281190  \n",
       "2              1.955000        1.152255                 0.201391  \n",
       "3              2.175786        6.046041                 4.935010  \n",
       "4              0.729259       -0.868353                -0.397100  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The data is in a dataframe \"df\". Standardize this data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.153111e-15</td>\n",
       "      <td>-6.568462e-15</td>\n",
       "      <td>-6.993039e-16</td>\n",
       "      <td>-8.553985e-16</td>\n",
       "      <td>6.081447e-15</td>\n",
       "      <td>-1.136369e-15</td>\n",
       "      <td>-2.997017e-16</td>\n",
       "      <td>1.023981e-15</td>\n",
       "      <td>-1.860648e-15</td>\n",
       "      <td>-1.504752e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.297713e-15</td>\n",
       "      <td>1.742016e-15</td>\n",
       "      <td>-1.198807e-15</td>\n",
       "      <td>6.118909e-16</td>\n",
       "      <td>-5.094929e-15</td>\n",
       "      <td>-2.122887e-15</td>\n",
       "      <td>6.118909e-16</td>\n",
       "      <td>-1.998011e-16</td>\n",
       "      <td>-2.422589e-15</td>\n",
       "      <td>2.497514e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.029648e+00</td>\n",
       "      <td>-2.229249e+00</td>\n",
       "      <td>-1.984504e+00</td>\n",
       "      <td>-1.454443e+00</td>\n",
       "      <td>-3.112085e+00</td>\n",
       "      <td>-1.610136e+00</td>\n",
       "      <td>-1.114873e+00</td>\n",
       "      <td>-1.261820e+00</td>\n",
       "      <td>-2.744117e+00</td>\n",
       "      <td>-1.819865e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.726901e+00</td>\n",
       "      <td>-2.223994e+00</td>\n",
       "      <td>-1.693361e+00</td>\n",
       "      <td>-1.222423e+00</td>\n",
       "      <td>-2.682695e+00</td>\n",
       "      <td>-1.443878e+00</td>\n",
       "      <td>-1.305831e+00</td>\n",
       "      <td>-1.745063e+00</td>\n",
       "      <td>-2.160960e+00</td>\n",
       "      <td>-1.601839e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.893853e-01</td>\n",
       "      <td>-7.259631e-01</td>\n",
       "      <td>-6.919555e-01</td>\n",
       "      <td>-6.671955e-01</td>\n",
       "      <td>-7.109628e-01</td>\n",
       "      <td>-7.470860e-01</td>\n",
       "      <td>-7.437479e-01</td>\n",
       "      <td>-7.379438e-01</td>\n",
       "      <td>-7.032397e-01</td>\n",
       "      <td>-7.226392e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.749213e-01</td>\n",
       "      <td>-7.486293e-01</td>\n",
       "      <td>-6.895783e-01</td>\n",
       "      <td>-6.421359e-01</td>\n",
       "      <td>-6.912304e-01</td>\n",
       "      <td>-6.810833e-01</td>\n",
       "      <td>-7.565142e-01</td>\n",
       "      <td>-7.563999e-01</td>\n",
       "      <td>-6.418637e-01</td>\n",
       "      <td>-6.919118e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.150816e-01</td>\n",
       "      <td>-1.046362e-01</td>\n",
       "      <td>-2.359800e-01</td>\n",
       "      <td>-2.951869e-01</td>\n",
       "      <td>-3.489108e-02</td>\n",
       "      <td>-2.219405e-01</td>\n",
       "      <td>-3.422399e-01</td>\n",
       "      <td>-3.977212e-01</td>\n",
       "      <td>-7.162650e-02</td>\n",
       "      <td>-1.782793e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.690395e-01</td>\n",
       "      <td>-4.351564e-02</td>\n",
       "      <td>-2.859802e-01</td>\n",
       "      <td>-3.411812e-01</td>\n",
       "      <td>-4.684277e-02</td>\n",
       "      <td>-2.695009e-01</td>\n",
       "      <td>-2.182321e-01</td>\n",
       "      <td>-2.234689e-01</td>\n",
       "      <td>-1.274095e-01</td>\n",
       "      <td>-2.164441e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.693926e-01</td>\n",
       "      <td>5.841756e-01</td>\n",
       "      <td>4.996769e-01</td>\n",
       "      <td>3.635073e-01</td>\n",
       "      <td>6.361990e-01</td>\n",
       "      <td>4.938569e-01</td>\n",
       "      <td>5.260619e-01</td>\n",
       "      <td>6.469351e-01</td>\n",
       "      <td>5.307792e-01</td>\n",
       "      <td>4.709834e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.220158e-01</td>\n",
       "      <td>6.583411e-01</td>\n",
       "      <td>5.402790e-01</td>\n",
       "      <td>3.575891e-01</td>\n",
       "      <td>5.975448e-01</td>\n",
       "      <td>5.396688e-01</td>\n",
       "      <td>5.311411e-01</td>\n",
       "      <td>7.125100e-01</td>\n",
       "      <td>4.501382e-01</td>\n",
       "      <td>4.507624e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.971288e+00</td>\n",
       "      <td>4.651889e+00</td>\n",
       "      <td>3.976130e+00</td>\n",
       "      <td>5.250529e+00</td>\n",
       "      <td>4.770911e+00</td>\n",
       "      <td>4.568425e+00</td>\n",
       "      <td>4.243589e+00</td>\n",
       "      <td>3.927930e+00</td>\n",
       "      <td>4.484751e+00</td>\n",
       "      <td>4.910919e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.094189e+00</td>\n",
       "      <td>3.885905e+00</td>\n",
       "      <td>4.287337e+00</td>\n",
       "      <td>5.930172e+00</td>\n",
       "      <td>3.955374e+00</td>\n",
       "      <td>5.112877e+00</td>\n",
       "      <td>4.700669e+00</td>\n",
       "      <td>2.685877e+00</td>\n",
       "      <td>6.046041e+00</td>\n",
       "      <td>6.846856e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean radius  mean texture  mean perimeter     mean area  \\\n",
       "count  5.690000e+02  5.690000e+02    5.690000e+02  5.690000e+02   \n",
       "mean  -3.153111e-15 -6.568462e-15   -6.993039e-16 -8.553985e-16   \n",
       "std    1.000880e+00  1.000880e+00    1.000880e+00  1.000880e+00   \n",
       "min   -2.029648e+00 -2.229249e+00   -1.984504e+00 -1.454443e+00   \n",
       "25%   -6.893853e-01 -7.259631e-01   -6.919555e-01 -6.671955e-01   \n",
       "50%   -2.150816e-01 -1.046362e-01   -2.359800e-01 -2.951869e-01   \n",
       "75%    4.693926e-01  5.841756e-01    4.996769e-01  3.635073e-01   \n",
       "max    3.971288e+00  4.651889e+00    3.976130e+00  5.250529e+00   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count     5.690000e+02      5.690000e+02    5.690000e+02         5.690000e+02   \n",
       "mean      6.081447e-15     -1.136369e-15   -2.997017e-16         1.023981e-15   \n",
       "std       1.000880e+00      1.000880e+00    1.000880e+00         1.000880e+00   \n",
       "min      -3.112085e+00     -1.610136e+00   -1.114873e+00        -1.261820e+00   \n",
       "25%      -7.109628e-01     -7.470860e-01   -7.437479e-01        -7.379438e-01   \n",
       "50%      -3.489108e-02     -2.219405e-01   -3.422399e-01        -3.977212e-01   \n",
       "75%       6.361990e-01      4.938569e-01    5.260619e-01         6.469351e-01   \n",
       "max       4.770911e+00      4.568425e+00    4.243589e+00         3.927930e+00   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count   5.690000e+02            5.690000e+02  ...  5.690000e+02   \n",
       "mean   -1.860648e-15           -1.504752e-15  ... -2.297713e-15   \n",
       "std     1.000880e+00            1.000880e+00  ...  1.000880e+00   \n",
       "min    -2.744117e+00           -1.819865e+00  ... -1.726901e+00   \n",
       "25%    -7.032397e-01           -7.226392e-01  ... -6.749213e-01   \n",
       "50%    -7.162650e-02           -1.782793e-01  ... -2.690395e-01   \n",
       "75%     5.307792e-01            4.709834e-01  ...  5.220158e-01   \n",
       "max     4.484751e+00            4.910919e+00  ...  4.094189e+00   \n",
       "\n",
       "       worst texture  worst perimeter    worst area  worst smoothness  \\\n",
       "count   5.690000e+02     5.690000e+02  5.690000e+02      5.690000e+02   \n",
       "mean    1.742016e-15    -1.198807e-15  6.118909e-16     -5.094929e-15   \n",
       "std     1.000880e+00     1.000880e+00  1.000880e+00      1.000880e+00   \n",
       "min    -2.223994e+00    -1.693361e+00 -1.222423e+00     -2.682695e+00   \n",
       "25%    -7.486293e-01    -6.895783e-01 -6.421359e-01     -6.912304e-01   \n",
       "50%    -4.351564e-02    -2.859802e-01 -3.411812e-01     -4.684277e-02   \n",
       "75%     6.583411e-01     5.402790e-01  3.575891e-01      5.975448e-01   \n",
       "max     3.885905e+00     4.287337e+00  5.930172e+00      3.955374e+00   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count       5.690000e+02     5.690000e+02          5.690000e+02   \n",
       "mean       -2.122887e-15     6.118909e-16         -1.998011e-16   \n",
       "std         1.000880e+00     1.000880e+00          1.000880e+00   \n",
       "min        -1.443878e+00    -1.305831e+00         -1.745063e+00   \n",
       "25%        -6.810833e-01    -7.565142e-01         -7.563999e-01   \n",
       "50%        -2.695009e-01    -2.182321e-01         -2.234689e-01   \n",
       "75%         5.396688e-01     5.311411e-01          7.125100e-01   \n",
       "max         5.112877e+00     4.700669e+00          2.685877e+00   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count    5.690000e+02             5.690000e+02  \n",
       "mean    -2.422589e-15             2.497514e-15  \n",
       "std      1.000880e+00             1.000880e+00  \n",
       "min     -2.160960e+00            -1.601839e+00  \n",
       "25%     -6.418637e-01            -6.919118e-01  \n",
       "50%     -1.274095e-01            -2.164441e-01  \n",
       "75%      4.501382e-01             4.507624e-01  \n",
       "max      6.046041e+00             6.846856e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compute the covariance matrix of the whole dataset\n",
    "- The variance of a variable measures the *spread* of its values.\n",
    "- The covariance of two variables $X$ and $Y$ measures how much they vary from the mean with respect to each other. It gives you an intuition of how the value of $Y$ will change if the value of $X$ changes. If you calculate the covariance between one dimension and itself, you get the variance. The covariance can be computed as follows: $Cov(X,Y) = \\sum_{i=1}^n\\left(X_i - \\bar{X} \\right) \\left(Y_i - \\bar{Y} \\right)$\n",
    "- If we have a data set with more than 2 dimensions, there is more than one covariance measurement that can be calculated. A useful way to get all the possible covariance values between all the different dimensions is to calculate them all and put them in a matrix: the covariance matrix. The covariance matrix of $X$ can be calculated easily as $C = (X - X_{mean})^T \\cdot (X - X_{mean})$. Note that $X_{mean}$ is a matrix where all elements of column $i$ are identical and have the mean value of feature $x_i$ in the dataset. Because the variance between feature $x_i$ and $x_j$ is the same as the variance between feature $x_j$ and $x_i$, $C$ is a symmetric matrix.\n",
    "\n",
    "<font color='red'>Task: Calculate the covariance matrix from the scaled data. This is made easy in pandas using the .cov() method: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.cov.html</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = ...\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(data=cov_matrix.round(1), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compute eigenvectors and the corresponding eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **eigenvectors** $v$ of a matrix $A$ are the vectors $v$ such that if you multiply $A$ with $v$, you get a multiple of $v$.\n",
    "$$ A v = \\lambda v $$\n",
    "The scalar $\\lambda$ is called the **eigenvalue** that belongs to the eigenvector $v$. Eigenvalues and eigenvectors are always coming in pairs - we speak about **eigenpairs**. \n",
    "\n",
    "intuitively, you can visualize a vector as a point in n-dimensional space. The matrix $A$ can then be seen as a **transformation matrix**. If you multiply this matrix with a vector, the result is another vector that is transformed from its original position. This is visualized in the animation below. The red vectors have changed their directions but the blue and pink ones still point in the same direction although their length has changed. These are the **eigenvectors** and their scaling factors are the **eigenvalues**.\n",
    "\n",
    "<div style=\"float:left clear:both\">\n",
    "        <img src=\"images/eigenvector.gif\" width=\"300\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "Eigenvectors have the following properties:\n",
    "- They can only be found for square matrices.\n",
    "- Not every square matrix has eigenvectors.\n",
    "- Given an n*n matrix that does have eigenvectors, there are n of them.\n",
    "- Eigenvectors are not unique: if $v$ is an eigenvector with eigenvalue $\\lambda$, then also $\\alpha v$ is an eigenvector, with eigenvalue $\\lambda / \\alpha$. In the rest, we consider only eigenvectors $v$ of unit length (with the associated $\\lambda_i$).\n",
    "\n",
    "Most importantly, all the eigenvectors of a matrix are perpendicular, i.e. at right angles to each other, no matter how many dimensions you have. This is important because it means that you can express the data in terms of these perpendicular eigenvectors, instead of expressing them in terms of the original x and y axes. Any $dxd$ symmetric matrix $A$ can be decomposed into the sum of its $d$ eigenvector products. By convention, we sort the eigenvalues $\\lambda_i$ by size, so $\\lambda_i >= \\lambda_{i+1}$ (assuming $v$ is a row vector):\n",
    "$$\n",
    "A = \\sum_{i=1}^d \\lambda_i v_i v_i^T\n",
    "$$\n",
    "\n",
    "Since the covariance matrix is square, we can calculate the eigenvectors and eigenvalues for this matrix. As a result, we get d-dimensional vectors that describe the axes in the original data that have the highest variation.\n",
    "\n",
    "<font color='red'>Task: Calculate the eigenvectors and eigenvalues from our covariance matrix. This is again made easy using numpy: https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Sort the eigenvectors by decreasing eigenvalues and choose k eigenvectors with the largest eigenvalues to form a d × k dimensional matrix W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now combine the insights of above. The covariance matrix $C$, calculated on dataset $X$, is a symmetric matrix. This means $C$ has $d$ orthogonal eigenvectors, which are the principal components of the dataset matrix $X$. Also, $C$ can be composed into the sum of its eigenpairs:\n",
    "\n",
    "$$\n",
    "C = \\sum_{i=1}^d \\lambda_i v_i v_i^T\n",
    "$$\n",
    "\n",
    "Remember that it is a convention to sort the eigenvalues in decreasing order. If we use only the first $k$ terms in the summation above, we still get a good approximation of the covariance. \n",
    "\n",
    "Dimensionality reduction by PCA thus means to project your data on the $k$ eigenvectors with the $k$ largest eigenvalues.\n",
    "\n",
    "<font color='red'>Task: Extract the 2 eigenvectors with the highest eigenvalues</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Use this 2 x 30 eigenvector matrix to transform the samples onto the new subspace.\n",
    "<font color='red'>Task: Transform the data points to the new coordinates and visualize this as a scatter plot.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "ax = sns.scatterplot(x=result[:,1],y=result[:,0],hue=cancer['target'],legend=False);\n",
    "ax.set(xlabel='$z_1$', ylabel='$z_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Task: What do the different values in the eigenvectors represent ?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you have achieved. You have represented the original 30-dimensional dataset with only 2 features. As the plot above, you did not lose much valuable information: the two clusters ('benign') and ('malign') can be relatively easily separated!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Task: What happens if you use the two least important directions in the data ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "ax = sns.scatterplot(x=bad_result[:,0],y=bad_result[:,1],hue=cancer['target'],legend=False);\n",
    "ax.set(xlabel='$z_1$', ylabel='$z_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA in Scikit-learn\n",
    "As in all the previous assignments, there is a public available implementation available in Scikit-learn:  https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA with 2 components. Transform the data and plot the result. Documentation is at: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "data_reduced = pca.fit_transform(scaled_data)\n",
    "\n",
    "ax = sns.scatterplot(x=data_reduced[:,0],y=data_reduced[:,1],hue=cancer['target'],legend=False);\n",
    "ax.set(xlabel='$z_1$', ylabel='$z_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we determine the number of principal components?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, we manually specified $k=2$ as the number of dimensions to reduce the dataset to. The choice for $k=2$ was mostly out of convenience, since it allowed us to nicely visualize the results. Obviously, in many case $k=2$might be too restrictive. The lower $k$, the more we compress our dataset, but the more information about the variance we throw away. So, how to determine the optimal number of $k$?\n",
    "\n",
    "Remember that the principal components were the eigenvectors $v_i$ (with unit length) of the covariance matrix C, with eigenvalues sorted in decreasing order ($\\lambda_i > \\lambda_{i+1}$).\n",
    "\n",
    "$$\n",
    "C = \\sum_{i=1}^d \\lambda_i v_i v_i^T\n",
    "$$\n",
    "\n",
    "Since (by convention) our eigenvectors have unit length, the ratio of the variance explained by the first $k$ principal components is:\n",
    "$$\n",
    "\\frac{\\lambda_1 + \\lambda_2 + \\dotsb + \\lambda_k}{\\lambda_1 + \\lambda_2 + \\dotsb + \\lambda_k + \\dotsb + \\lambda_d}\n",
    "$$\n",
    "\n",
    "\n",
    "By plotting this ratio of explained variance as a function of $k$, we can apply the same elbow method as we used to determine the number of clusters in k-means clustering.\n",
    "\n",
    "<font color='red'>Task: Create a new PCA object without specifying the number of components to use. The ratio above is available as an attribute of the pca object. You get the correct values by calculating a cumulative sum (np.cumsum) on this pca attribute.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Task: With this insight, how much components would you use on our breast cancer dataset?.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE\n",
    "A special case of dimensionality reduction is when the output number of dimensions is two (or three). This is done to manually inspect the data. PCA works fine for this \n",
    "but **T-distributed Stochastic Neighbor Embedding (t-SNE)** often gives more interpretable results if the goal is visualization.\n",
    "\n",
    "t-SNE allows for a non-linear projection of the data while PCA only did a linear combination of features. The goal of t-SNE is not to explain the variance in the data but rather to use the local relationships between points to create a low-dimensional mapping. Two points that are close together in the high dimensional space will also be close together in the low dimensional space. This is not necessarily the case with PCA.\n",
    "\n",
    "\n",
    "<font color='red'>Task: Use the scikit-learn t-SNE implementation on this dataset.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "...\n",
    "ax = sns.scatterplot(x=data_reduced[:,0],y=data_reduced[:,1],hue=cancer['target'],legend=False);\n",
    "ax.set(xlabel='$z_1$', ylabel='$z_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "- Be careful when using t-SNE, it is easy to misinterpret the output. See https://distill.pub/2016/misread-tsne/\n",
    "- t-SNE does not define a function to reduce dimensionality, unlike PCA; t-SNE has no parameters, and directly optimizes the embeddings. In other words, you can train a t-SNE model on some data, but you can't use it to reduce the dimensionality of some new data points. You cannot use it as input for a classification model since you are unable to make predictions for new data.\n",
    "- t-SNE is not deterministic, it will result in a different embedding every time. The optimization problem is also **non-convex** and might get stuck in a **local minimum**. \n",
    "- t-SNE involves hyperparameters to be tuned unlike PCA which does not have any hyperparameters. Handing hyperparameters incorrectly may lead to unwanted results.\n",
    "- The PCA as explained in this sessions performs a linear combination of features. To enable a non-linear combination, you can use the **kernel trick** as explained in the next session. This results in **kernel PCA**.\n",
    "- t-SNE has a quadratic time and space complexity in the number of data points. This makes it particularly slow for large datasets. It is possible to first use PCA to reduce the dimensionality before running t-SNE in this case.\n",
    "- UMAP is a more recent algorithm that often gives superior results than t-SNE: https://umap-learn.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sessions, we worked with data stored in a tabular format. The rows represented individual datapoints and there was a column for each feature. This makes it easy for use to use it directly as input to a machine learning model that expects a matrix as input.\n",
    "\n",
    "For many real world problems, you will need to first define and extract these features manually. In this exercise we will investigate how this can be done for textual data. Text data is a type of **unstructured data** since there is no predefined format for it. \n",
    "\n",
    "When working with textual data, you need to perform two steps prior to training your ML model **Data preprocessing** and **feature extraction**.\n",
    "\n",
    "The preprocessing can include:\n",
    "- **Tokenization**: converting sentences to words\n",
    "- Removing unnecessary punctuation\n",
    "- Removing urls, html markup, ...\n",
    "- Removing **stop words**, frequent words such as \"the\", \"is\", \"a\", etc. that do not have specific semantic\n",
    "- **Stemming**: words are reduced to a root by removing inflection through dropping unnecessary characters, usually a suffix.\n",
    "- **Lemmatization**: Another approach to remove inflection by determining the part of speech and utilizing detailed database of the language.\n",
    "\n",
    "The result of the preprocessing step is a list of words. We can use different approaches to extract features from these words to obtain numerical representations that we can give to machine learning models. The goal of this feature extraction step is to take a **document** (a collection of words) and to transform it into a numerical feature vector. The documents will vary in size but the feature vector usually has a fixed size. The collection of all documents is often called the **corpus** in text processing. We often use statistics of the corpus to obtain a feature representation for a single document.\n",
    "- **Bag of Words (BOW)**: This is the simplest possible representation: We make the list of all the unique words in the text corpus, this is called the **vocabulary**. Then we can represent each document as a vector that indicates how many times each word from the vocabulary occurs in the document. This is a very simple method but can be useful in certain applications. In SPAM detection, we can expect that the words \"stock\", \"Viagra\", and \"buy\" can be indicative of SPAM emails. \n",
    "- A disadvantage is that this technique is only concerned with the occurrence of the word and not with the order of the words. It also treats each word independently.  You can solve this by introducing **n-gram generation** in the preprocessing step. n-grams are created by extracting all sequential n words from the document. **Bi-grams** for example extract all sequential pairs. The sentence \"The president of the US is Joe Biden\" will be transformed into \\[\"The president\", \"president of\", \"of the\", \"the US\", \"US is\", \"is Joe\", \"Joe Biden\"]. This is useful to capture terms consisting of multiple words. Bi-grams allow you to recognize both \"Donald Trump\" and \"Donald Duck\". Alternatively, you can also extract **tri-grams** (n=3).\n",
    "- **TF-IDF**: shorthand for **term frequency-inverse document frequency**. Is a way of normalizing the BOW approach. It is the **term frequency** divided by the **document frequency**. Instead of just counting how many times a certain word occurs in the document (the term frequency) we divide it by the document frequency (the number of documents this word occurs in). A word that occurs often in a certain document but does not occur often in other documents is probably an important word for this document. \n",
    "- **Word embeddings**: Are the most advanced technique. A word embedding method transforms a word into a point in a high dimensional space where words that have a similar meaning are mapped to similar points. Word embeddings can be seen as a form of dimensionality reduction. This allows us to learn more complex relationships. The most common Word embedding technique is **Word2Vec**. It makes the assumption that two words that occur at a similar position in different sentences have more or less the same meaning. If you have the two sentences \"BMW is a German car manufacturer\" and \"Tesla is an American automobile manufacturer\", you can infer that \"BMW\" and \"Tesla\", \"German\" and \"American\" and \"car\" and \"automobile\" are related. Word embeddings are trained on a large text corpus such as wikipedia. You can find more information at https://pathmind.com/wiki/word2vec#import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data: health Tweets\n",
    "In the following exercise we will use TF-IDF to extract features from \"Health News in Twitter Data Set\". This dataset contains different sets of sample tweets from various news channels like CNN, NYTimes, CBC etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#this function returns a dict with tweets loaded\n",
    "def read_all_tweets():\n",
    "    all_tweets = {}\n",
    "    file = open(\"data/nytimeshealth.txt\", \"r\",encoding=\"utf8\")\n",
    "    lines = file.readlines()\n",
    "    for index, line in enumerate(lines):\n",
    "        parts = line.split(sep=\"|\", maxsplit=2)\n",
    "        tweet = \"\".join(parts[2:len(parts)])\n",
    "        all_tweets[index] = tweet\n",
    "    file.close()\n",
    "    return all_tweets\n",
    "\n",
    "\n",
    "tweets_dict = read_all_tweets()\n",
    "tweets = tweets_dict.values()\n",
    "\n",
    "df = pd.DataFrame(list(tweets_dict.items()),columns=[\"Tweet Index\",\"Tweet\"])\n",
    "print(\"Number of tweets in dataset: \",df.shape[0])\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Task: Follow the instructions at https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html to preprocess the data and to extract TF-IDF features. Experiment with different ngrams and the *min_df* and *max_df* parameters. These last two parameters allow you to remove terms that are present in only a few documents or in most of the documents.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Task: How many features are extracted ? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Task: Look at the first tweet, what keywords are extracted and what is their tf-idf score ? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.at[0, \"Tweet\"])\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Task: Use these features to find the most similar documents using a NearestNeighbors algorithm. </font>\n",
    "\n",
    "To calculate similarities you will need to define a **distance function**. The default **euclidian distance** is easy to interpret as it just calculates the length of the straight line between two points. In NLP, the cosine distance is often more useful. It looks at the angle between two vectors and is more robust in case of different document lengths. There are more advanced functions such as **Jaccard Similarity** or **Word Mover’s Distance** that are useful for some cases. See https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html for an overview of the metrics that are supported by Scikit-learn.\n",
    "\n",
    "<font color='red'>Task: Experiment with different distance functions. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "- We extracted the features from the text and used them to find similar tweets. In real applications you will use these features as input to a machine learning model for classification, clustering, regression, ...\n",
    "- Since text documents are characterized by a large amount of features, it might be interesting to apply dimensionality reduction first.\n",
    "- TF-IDF and similar techniques are commonly used in search engines. For every document (webpage, product, ...). A TF-IDF vector is extracted that describes the content. All these vectors are stored in an **inverted index** that maps terms to documents. When the user executes a query, we just have to return the documents where a certain search term was found to be important.\n",
    "- Because of their limited length, tweets are a difficult case for text feature extraction.\n",
    "- TF-IDF is very commonly used but recently there has been much interest in **vector embedding** techniques such as word2vec, doc2vec, GloVe or fasttext. These models learn an **embedding space**. A lower dimensional space that words can be mapped to. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located close to one another in the space. This has proven to be a very useful way to extract features from text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Alpaydin E., \"Introduction to Machine Learning\", 3rd edition.\n",
    "* Skiena, S., \"The Data Science Design Manual\".\n",
    "* Raschka S., \"Python Machine Learning\", 2nd edition.\n",
    "* Géron A., \"Hands-on Machine Learnign with Scikit-Learn and Tensorflow. 2nd edition.\n",
    "* Shlens J., \"A tutorial on PCA\". https://arxiv.org/pdf/1404.1100.pdf\n",
    "* datascienceplus.com - Principal Component Analysis (PCA) with Python. URL: https://datascienceplus.com/principal-component-analysis-pca-with-python/\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
